# Feedforward Neural Network with hyperparameter optimisation
This research project will demonstrate performance of different classifiers compared with the feed forward neural network using same dataset.
Dataset: Credit Card Fraud detection dataset.

The outcome of this project is to answer the following questions:
1. Which hyperparameters of the Feed Forward Neural network are most important for 
empirical performance of the model?
2. What values of these hyperparameters are most likely to produce good results?
3. Which classifiers are the most accurate on the dataset in order to achieve good results?

# Objective
![image](https://user-images.githubusercontent.com/92319220/232810206-f7fb007d-a545-4e88-ac33-cf2e4ee11c87.png)

# Dataset:
![image](https://user-images.githubusercontent.com/92319220/232810488-49ec3b13-bd89-4404-bf34-2a2147b3a8ac.png)

# Pseudocode
![image](https://user-images.githubusercontent.com/92319220/232810766-337638d0-cfdb-432f-a652-6e1766214999.png)
![image](https://user-images.githubusercontent.com/92319220/232810932-7c8a4a92-7e85-4bb2-a615-181173f2320b.png)
![image](https://user-images.githubusercontent.com/92319220/232811006-a8aced61-3a65-40d8-928d-1c5359a6bd53.png)
![image](https://user-images.githubusercontent.com/92319220/232811050-16b7b152-6070-4b37-8c2a-dd806f44bc82.png)

# Precision vs Accuracy
![image](https://user-images.githubusercontent.com/92319220/232811211-3f8d5c3d-eed8-4949-8d3f-af7b2f5e4f0b.png)

# Before Sampling:
![image](https://user-images.githubusercontent.com/92319220/232811364-a25b9f7c-6d1b-4331-ae3e-e63b2d47ad95.png)

# After Sampling:
![image](https://user-images.githubusercontent.com/92319220/232811492-7c823422-1d81-4310-a09b-dcf803dc4736.png)

# Experiments: Neural Network
![image](https://user-images.githubusercontent.com/92319220/232812179-69f3ead2-8011-44ba-b6f4-19d76f85617a.png)
![image](https://user-images.githubusercontent.com/92319220/232812252-a4b5b437-acbb-4e65-aae5-570033cacbed.png)

# Experiments: Decision Tree Classifier
![image](https://user-images.githubusercontent.com/92319220/232812348-3a06b5d7-e3cd-47f6-84f9-2b27b0ed08bc.png)
![image](https://user-images.githubusercontent.com/92319220/232812422-52a590c3-e3b4-4de7-96af-9d0e5626f36b.png)

# Experiments: Naive Bayes Classifier
![image](https://user-images.githubusercontent.com/92319220/232812529-c6318539-576e-4bc4-b2cf-25dc510deb7a.png)
![image](https://user-images.githubusercontent.com/92319220/232812575-5d38ceb0-926a-42d5-b2d6-bc74ad7c0ced.png)

# Experiments: Random Forest Classifier
![image](https://user-images.githubusercontent.com/92319220/232812707-50b80a09-7f2e-4c2a-9cef-d16f3116b3a8.png)
![image](https://user-images.githubusercontent.com/92319220/232812768-e54875f2-ffd2-4835-a89d-ee9cbdeee451.png)


# Results : before Sampling
![image](https://user-images.githubusercontent.com/92319220/232813296-acb69638-6f31-464b-8453-5bdc3dcbd97e.png)

# Results : after sampling
![image](https://user-images.githubusercontent.com/92319220/232813421-2ac118c1-77d7-46e4-bdd3-620cef6c171f.png)

# Conclusion:
The experimental results show that the Random Forest outperformed other machine learning algorithms, achieving the greatest accuracy of **97.44%**.
![image](https://user-images.githubusercontent.com/92319220/232813785-3f2fbb2c-8e9b-4888-bce3-b90fd79ac1f1.png)
![image](https://user-images.githubusercontent.com/92319220/232813805-ab5b4fec-2f87-411f-9657-b93ad3e77986.png)







